########################################################################
# Usage:
# All parameters could be specified by argparse, e.g. simply run the python script with ``--model_path xxx'' will change
# ``model_path'' parameter during running. Nested params ``--ddim.schedule_params.ddpm_num_steps xxx'' is also supported.
########################################################################

########################################################################
##  basic configs
########################################################################
model_path: ./checkpoints/256x256_diffusion.pt
seed: 42
use_git: false
n_samples: 1
n_iter: 1
algorithm: o_ddim
resume: false # will load previous results if there are some
mode: deblur # sr, deblur
scale: 2
debug: false

########################################################################
## algorithm specific configs
########################################################################
ddim:
  ddim_sigma: 0.0
  start_step: 150
  schedule_params:
    num_inference_steps: 250
    ddpm_num_steps: 250
    schedule_type: linear
    jump_length: 1
    jump_n_sample: 1
    use_timetravel: false
    time_travel_filter_type: none

optimize_xt:
  optimize_xt: true
  num_iteration_inp: 2 # G步梯度下降，即优化xt的次数
  lr_xt: 0.02
  lr_xt_decay: 1.012
  use_smart_lr_xt_decay: true
  use_adaptive_lr_xt: true
  coef_xt_reg: 0.01
  coef_xt_reg_decay: 1.00
  optimize_before_time_travel: true


########################################################################
### unet configs, no need to change
########################################################################
cond_y:
class_cond: true
attention_resolutions: 32,16,8
diffusion_steps: 1000
learn_sigma: true
noise_schedule: linear
num_channels: 256
num_head_channels: 64
num_heads: 4
num_res_blocks: 2
resblock_updown: true
use_fp16: true
use_scale_shift_norm: true
lr_kernel_n_std: 2
num_samples: 100
show_progress: true
timestep_respacing: '250'
use_kl: false
predict_xstart: false
rescale_timesteps: false
rescale_learned_sigmas: false

classifier_use_fp16: false
classifier_width: 128
classifier_depth: 2
classifier_attention_resolutions: 32,16,8
classifier_use_scale_shift_norm: true
classifier_resblock_updown: true
classifier_pool: attention
classifier_scale: 1.0 # 分类器引导强度

num_heads_upsample: -1
channel_mult: ''
dropout: 0.0
use_checkpoint: false
use_new_attention_order: false
clip_denoised: true
use_ddim: false
image_size: 256
respace_interpolate: false